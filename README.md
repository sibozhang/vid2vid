# vid2vid
modifed version of [vid2vid](https://github.com/NVIDIA/vid2vid) for [Speech2Video](https://github.com/sibozhang/Speech2Video) and [Text2Video](https://github.com/sibozhang/Speech2Video).

# Setup
```
git clone git@github.com:sibozhang/vid2vid.git
```

# Trained model
Please build 'checkpoints' folder in the current folder and put trained model in it.

VidTIMIT fadg0 (Female) [Download](https://www.dropbox.com/sh/lk6et49v2uyfzjx/AADAFAp02_b3FQchaYxOZ0EMa?dl=0)

## Citation
Speech2Video Synthesis with 3D Skeleton Regularization and Expressive Body Poses

Miao Liao*, Sibo Zhang*, Peng Wang, Hao Zhu, Xinxin Zuo, Ruigang Yang. [PDF](https://arxiv.org/pdf/2007.09198.pdf) [Result Video](https://youtu.be/MUlRtgbGeUs)
[1 min Spotlight](https://youtu.be/04oqf7kDzXo) [10 min Presentation](https://youtu.be/E8Dvef0Z4sw)
```
@inproceedings{liao2020speech2video,
  title={Speech2video synthesis with 3D skeleton regularization and expressive body poses},
  author={Liao, Miao and Zhang, Sibo and Wang, Peng and Zhu, Hao and Zuo, Xinxin and Yang, Ruigang},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  year={2020}
}
```

## Ackowledgements
This code is based on the vid2vid framework.
